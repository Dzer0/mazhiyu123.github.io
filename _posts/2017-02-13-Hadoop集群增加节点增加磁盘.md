---
published: true
layout: post
title: Hadoop集群 增加节点，增加磁盘
category: Hadoop
tags: 
  - Hadoop
  - Linux
time: 2017.02.13 14:48:00
excerpt: Hadoop集群 增加节点，增加磁盘.
         由于Slave-3的文件系统损坏，目前还没有找到可行的修复方法。现在，增加一个节点Slave-4来代替Slave-3的位置。
---

由于Slave-3的文件系统损坏，目前还没有找到可行的修复方法。现在，增加一个节点Slave-4来代替Slave-3的位置。

1. 在虚拟机中新建一个机器。  
2. 设置静态IP
3. 将修改/etc/hosts
    ```
    192.168.102.10 master
    192.168.102.11 slave-1
    192.168.102.12 slave-2
    192.168.102.13 slave-3
    192.168.102.14 slave-4
    ```
    在然后在其他节点hosts文件中增加
    ```
    192.168.102.14 slave-4
    ```
4. 修改hostname 命令hostnamectl set-hostname Slave-4
    通过hostname命令查看修改结果
5. 关闭防火墙
    ```
    systemctl stop firewalld.service      //停止firewall
    systemctl disable firewalld.service //禁止firewall开机启动
    systemctl status firewalld.service //查看防火墙状态
    ```
6. 节点免密码登录
    使用命令
    ```    
    ssh-keygen -t rsa（一路回车）
    ```
    生成id_rsa（私钥）、id_rsa.pub（公钥）然后 
    ```
    cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
    ```
    将Salve-4的公钥拷贝到其他节点上，再将其他节点的公钥拷贝到Salve-4上
    ```
    Salve-4节点上执行
    ssh-copy-id -i  Master
    ssh-copy-id -i  slave-1
    ssh-copy-id -i  slave-2
    ssh-copy-id -i  slave-3(这里没有执行，待把slave-3修复了再执行)
    ```
    在其他节点执行
    ```
    ssh-copy-id -i  slave-4
    ```
    再用ssh验证相互之间的免密码登陆
    ```
    ssh slave-4(master,等hostname)
    ```
7. 在/usr/local/hadoop2.7.2/etc/hadoop/slaves 中增加slave-4
8. 将其他一个节点的/etc/profile,/usr/local目录下文件传输到slave-4中，目录位置不变
    ```
    scp -r /etc/profile root@slave-4:/etc/
    scp -r /usr/local root@slave-4:/usr/
    ```
9. 修改系统默认JDK
    ```
    update-alternatives --install /usr/bin/java java /usr/local/jdk1.8/bin/java 300
    update-alternatives --install /usr/bin/java javac /usr/local/jdk1.8/bin/javac 300
    update-alternatives --install /usr/bin/jar jar /usr/local/jdk1.8/bin/jar 300
    update-alternatives --config java
    然后选择
       4           /usr/local/jdk1.8/bin/java
    这一行
    ```

10. 在[虚拟磁盘扩容](http://note.youdao.com/)已经实现了虚拟机中的扩容(分区，创建文件系统，挂载)，这里实现HDFS中识别出增加的容量
    删除hdfs-site.xml中dfs.data.dir指定的文件
    ```
    <property>  
    <name>dfs.data.dir</name>  
    <value>/usr/local/data</value>  
    <description>datanode上数据块的物理存储位置</description>  
    </property>
    ```
    删除core-site.xml中hadoop.tmp.dir指定的文件，删除/usr/local/hadoop 放着各个节点ID会不一样。
    ```
    <property>
    <name>hadoop.tmp.dir</name>
    <value>/usr/local/hadoop/tmp</value>
    </property>
    
    ```
    格式化namenode
    ```
    hdfs namenode -format
    ```
    格式化完毕,原来的数据全部被清空了。产生了一个新的hdfs
    查看信息
    ```
     hdfs dfsadmin -report
     ```
11.第10个步骤可能是多余的没必要
在增加磁盘的情况下，只需要在挂载完硬盘之后修改hdfs-site.xml文件即可。
```
<property>  
    <name>dfs.data.dir</name>  
    <value>/usr/local/data==,/newdisk/hadoop-data/==</value>  
    <description>datanode上数据块的物理存储位置</description>  
```
