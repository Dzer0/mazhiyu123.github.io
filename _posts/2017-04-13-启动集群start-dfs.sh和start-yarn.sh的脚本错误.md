---
published: true
layout: post
title: 启动集群start-dfs.sh和start-yarn.sh的脚本错误
category: Hadoop
tags: 
  - Hadoop
time: 2017.04.13 12:16:00
excerpt:   启动集群start-dfs.sh和start-yarn.sh的脚本错误
---

在部署好集群准备启动的时候，运行shell脚本start-dfs.sh出现错误,没有用户定义。

```
    "ERROR: Attempting to launch hdfs namenode as root"
    "ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting launch."
       
    "ERROR: Attempting to launch hdfs datanode as root"
    "ERROR: but there is no HDFS_DATANODE_USER defined. Aborting launch."
       
    "ERROR: Attempting to launch hdfs journalnode as root"
    "ERROR: but there is no HDFS_JOURNALNODE_USER defined. Aborting launch."

```

在hadoop-env.sh中添加下面变量后，dfs可以正常启动

```
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_JOURNALNODE_USER=root
```

运行脚本start-yarn.sh出现了上面一样的ERROR

```
"ERROR: Attempting to launch yarn /usr/cluster/hadoop3.0-alpha2/hadoop-3.0.0-alpha2/bin/yarn as root"
    "ERROR: but there is no YARN_/USR/CLUSTER/HADOOP3.0-ALPHA2/HADOOP-3.0.0-ALPHA2/BIN/YARN_USER defined. Aborting launch."
       
    "ERROR: Attempting to launch yarn nodemanager as root"
    "ERROR: but there is no YARN_NODEMANAGER_USER defined. Aborting launch."
```

在hadoop-env.sh中添加下面的变量

```
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
```
NodeManager的ERROR消除了，ResourceManager的还在。

查看start-yarn.sh的源码

启动resourcemanager

```
# start resourceManager
HARM=$("${HADOOP_HDFS_HOME}/bin/hdfs" getconf -confKey yarn.resourcemanager.ha.enabled 2>&-)
if [[ ${HARM} = "false" ]]; then
  echo "Starting resourcemanager"
  hadoop_uservar_su yarn resourcemanager "${HADOOP_YARN_HOME}/bin/yarn" \
      --config "${HADOOP_CONF_DIR}" \
      --daemon start \
      resourcemanager
  (( HADOOP_JUMBO_RETCOUNTER=HADOOP_JUMBO_RETCOUNTER + $? ))
else
  logicals=$("${HADOOP_HDFS_HOME}/bin/hdfs" getconf -confKey yarn.resourcemanager.ha.rm-ids 2>&-)
  logicals=${logicals//,/ }
  for id in ${logicals}
  do
      rmhost=$("${HADOOP_HDFS_HOME}/bin/hdfs" getconf -confKey "yarn.resourcemanager.hostname.${id}" 2>&-)
      RMHOSTS="${RMHOSTS} ${rmhost}"
  done
  echo "Starting resourcemanagers on [${RMHOSTS}]"
  hadoop_uservar_su yarn "${HADOOP_YARN_HOME}/bin/yarn" \
      --config "${HADOOP_CONF_DIR}" \
      --daemon start \
      --workers \
      --hostnames "${RMHOSTS}" \
      resourcemanager
  (( HADOOP_JUMBO_RETCOUNTER=HADOOP_JUMBO_RETCOUNTER + $? ))
fi

```

确定nodemanager的

```
# start nodemanager
echo "Starting nodemanagers"
hadoop_uservar_su yarn nodemanager "${HADOOP_YARN_HOME}/bin/yarn" \
    --config "${HADOOP_CONF_DIR}" \
    --workers \
    --daemon start \
    nodemanager
(( HADOOP_JUMBO_RETCOUNTER=HADOOP_JUMBO_RETCOUNTER + $? ))

```

对比可以看到问题出在hadoop_uservar_su 这个shell函数上，在hadoop-3.0.0-alpha2\libexec目录下找到hadoop-functions.sh这个shell文件，在里面找到hadoop_uservar_su函数的实现

```
## @description  Execute a command via su when running as root
## @description  with extra support for commands that might
## @description  legitimately start as root (e.g., datanode)
## @description  (This is intended to
## @description  be used by the start-*/stop-* scripts.)
## @audience     private
## @stability    evolving
## @replaceable  no
## @param        user
## @param        commandstring
## @return       exitstatus
function hadoop_uservar_su
{

  ## startup matrix:
  #
  # if $EUID != 0, then exec
  # if $EUID =0 then
  #    if hdfs_subcmd_user is defined, call hadoop_su to exec
  #    if hdfs_subcmd_user is not defined, error
  #
  # For secure daemons, this means both the secure and insecure env vars need to be
  # defined.  e.g., HDFS_DATANODE_USER=root HDFS_DATANODE_SECURE_USER=hdfs
  # This function will pick up the "normal" var, switch to that user, then
  # execute the command which will then pick up the "secure" version.
  #

  declare program=$1
  declare command=$2
  shift 2

  declare uprogram
  declare ucommand
  declare uvar

  if hadoop_privilege_check; then
    uvar=$(hadoop_get_verify_uservar "${program}" "${command}")

    if [[ -n "${!uvar}" ]]; then
      hadoop_su "${!uvar}" "$@"
    else
      hadoop_error "ERROR: Attempting to launch ${program} ${command} as root"
      hadoop_error "ERROR: but there is no ${uvar} defined. Aborting launch."
      return 1
    fi
  else
    "$@"
  fi
}
```

对于hadoop_uservar_su这个函数，需要传入两个参数，第一个参数赋值给了变量program，第二个赋值给了command，然后会调用hadoop_get_verify_uservar这个函数来对用户进行验证。hadoop_get_verify_uservar函数的实现：

```
## @description  Get the environment variable used to validate users
## @audience     public
## @stability    stable
## @replaceable  yes
## @param        subcommand
## @return       string
function hadoop_get_verify_uservar
{
  declare program=$1
  declare command=$2
  declare uprogram
  declare ucommand

  if [[ -z "${BASH_VERSINFO[0]}" ]] \
     || [[ "${BASH_VERSINFO[0]}" -lt 4 ]]; then
    uprogram=$(echo "${program}" | tr '[:lower:]' '[:upper:]')
    ucommand=$(echo "${command}" | tr '[:lower:]' '[:upper:]')
  else
    uprogram=${program^^}
    ucommand=${command^^}
  fi

  echo "${uprogram}_${ucommand}_USER"
}

```

无论hadoop_uservar_su函数还是hadoop_get_verify_uservar函数都需要传入program和command这两个参数，但是在启动ResourceManager调用hadoop_uservar_su 的时候只传入了program没有传入正确的command，hadoop_uservar_su将"${HADOOP_YARN_HOME}/bin/yarn"当作command传入，从而导致了上面的错误。

```
echo "Starting resourcemanagers on [${RMHOSTS}]"
  hadoop_uservar_su yarn "${HADOOP_YARN_HOME}/bin/yarn" \
      --config "${HADOOP_CONF_DIR}" \
      --daemon start \
      --workers \
      --hostnames "${RMHOSTS}" \
      resourcemanager
```

修改
```
hadoop_uservar_su yarn "${HADOOP_YARN_HOME}/bin/yarn" \
```
加入第二个人参数resourcemanager,这个要和hadoop-env.sh中的
```
export YARN_RESOURCEMANAGER_USER=root
```
中间的部分相对应


```
hadoop_uservar_su yarn resourcemanager "${HADOOP_YARN_HOME}/bin/yarn" 
```

重新运行start-yarn.sh，启动成功。
