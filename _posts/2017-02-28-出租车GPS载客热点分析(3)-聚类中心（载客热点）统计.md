---
published: true
layout: post
title: 出租车GPS载客热点分析(3)-聚类中心（载客热点）统计
category: Hadoop
tags: 
  - Hadoop
time: 2017.02.28 17:44:00
excerpt: 经过了[出租车GPS载客热点分析(3)]这个步骤的数据聚类处理，已经将所有的数据点进行了聚类划分，每个数据点都被划分某一个聚类中心点。这个步骤比较简单就是统计每个聚类中心的热度。本质上是一个WordCount的作业。
---

经过了[出租车GPS载客热点分析(3)](http://mazhiyu.info/hadoop/2017/02/28/%E5%87%BA%E7%A7%9F%E8%BD%A6GPS%E8%BD%BD%E5%AE%A2%E7%83%AD%E7%82%B9%E5%88%86%E6%9E%90(2)-%E6%95%B0%E6%8D%AE%E7%82%B9Kmeans%E8%81%9A%E7%B1%BB)这个步骤的数据聚类处理，已经将所有的数据点进行了聚类划分，每个数据点都被划分某一个聚类中心点。这个步骤比较简单就是统计每个聚类中心的热度。本质上是一个WordCount的作业。

### 实现

![image](http://od4ghyr10.bkt.clouddn.com/Fetcer%E6%8B%89%E5%8F%96%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.png)

##### Mapper过程
数据输入
聚类中心ID | 纬度 | 经度  
---------|------|------
1|104.126265|30.650542
1|104.109529|30.670981
1|104.100514|30.683655
2|104.132750|30.626605
2|104.057351|30.692118
3|104.059651|30.691794
3|103.996712|30.608103
3|104.002031|30.632534
3|104.066190|30.568210
3|104.063678|30.599831


中间结果输出  
和数据输入一样

mapper实现
```
public class KmeansHotSpotMapper extends Mapper<LongWritable, Text, IntWritable, IntWritable>{
    
    IntWritable outMapValue = new IntWritable(1);
    
    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        String[] recordInfo = value.toString().split("\t");
        IntWritable outMapKey  = new  IntWritable(Integer.parseInt(recordInfo[0]));
        context.write(outMapKey, outMapValue);
    }
    
}
```
##### Reducer过程
结果输出
聚类中心ID | 上车点数量  
---------|------
1 | 3
2 | 2
3 | 5

Reducer实现
```
public class KmeansHotSpotReducer extends Reducer<IntWritable, IntWritable, IntWritable, IntWritable>{
    
    @Override
    protected void reduce(IntWritable key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
        int sum = 0;
        for(IntWritable value : values) {
            sum += value.get();
        }
        
        context.write(key, new IntWritable(sum));
    }
    
}
```


##### Combiner实现
```
public class KmeansHotSpotCombiner extends Reducer<IntWritable, IntWritable, IntWritable, IntWritable>{
    @Override
    protected void reduce(IntWritable key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException{
        int sum = 0;
        for(IntWritable value : values) {
            sum += value.get();
        }
        context.write(key, new IntWritable(sum));
    }
}

```

##### 启动类Driver
启动类Driver实现
```
public class KmeansHotSpotDriver  extends Configured implements Tool{
    
    public static void main(String[] args) throws Exception {
        ToolRunner.run(new Configuration(), new KmeansHotSpotDriver(), args);
    }
    
    public int run(String[] args) throws IllegalArgumentException, IOException, ClassNotFoundException, InterruptedException {
        Configuration conf = getConf();
        Job job = Job.getInstance(conf);
        
        job.setJobName("KmeansHotSpot");
        job.setJarByClass(KmeansHotSpotDriver.class);
        
        job.setMapperClass(KmeansHotSpotMapper.class);
        job.setReducerClass(KmeansHotSpotReducer.class);
        
        job.setMapOutputKeyClass(IntWritable.class);
        job.setMapOutputValueClass(IntWritable.class);
        job.setOutputKeyClass(IntWritable.class);
        job.setOutputValueClass(IntWritable.class);
        
        job.setCombinerClass(KmeansHotSpotCombiner.class);
        
        FileInputFormat.setInputPaths(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        
        return job.waitForCompletion(true) ? 0 : 1;
    }
}

```