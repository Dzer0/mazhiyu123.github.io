---
layout: post
title: "Tunnel上传下载相关命令"
date: 2017-05-10
excerpt: "Tunnel上传下载相关命令"
tags: [MaxCompute, Tunnel]
comments: true
---

整理自[文档](https://help.aliyun.com/knowledge_detail/51826.html?spm=5176.7840347.2.2.wJujpY)  
1. MaxCompute Tunnel 是什么？  
    MaxCompute Tunnel 是 MaxCompute 的数据通道，用户可以通过 Tunnel 向 MaxCompute 中上传或者下载数据。目前 Tunnel 仅支持表（不包括视图 View）数据的上传下载 。

2. BlockId 是否可以重复？  
    同一个 UploadSession 里的 blockId 不能重复。也就是说，对于同一个UploadSession，用一个 blockId 打开 RecordWriter，写入一批数据后，调用 close，然后再 commit 完成后，写入成功后不可以重新再用该 blockId 打开另一个 RecordWriter 写入数据。 Block 默认最多 20000 个，即 0-19999 。

3. Block 大小是否存在限制？  
    一个 block 大小上限 100GB，强烈建议大于 64M 的数据，每一个 Block 对应一个文件，小于 64MB 的文件统称为小文件，小文件过多将会影响使用性能。使用新版 BufferedWriter 可以更简单的进行上传功能避免小文件等问题 [Tunnel-SDK-BufferedWriter](https://help.aliyun.com/document_detail/51328.html?spm=5176.7751826.2.2.pelz68)

4. Session 是否可以共享使用，存在生命周期吗？  
    每个 Session 在服务端的生命周期为 24 小时，创建后 24 小时内均可使用，也可以跨进程/线程共享使用，但是必须保证同一个 BlockId 没有重复使用，分布式上传可以按照如下步骤：创建 Session ->数据量估算->分配 Block（例如线程1使用 0-100，线程 2 使用 100-200）->准备数据->上传数据-> Commit 所有写入成功的 Block 。

5. 遇到 Write/Read 超时或 IOException 怎么处理？  
    上传数据时，Writer 每写入 8KB 数据会触发一次网络动作，如果 120 秒内没有网络动作，服务端将主动关闭连接，届时 Writer 将不可用，请重新打开一个新的 Writer 写入 。  
    建议使用 [Tunnel-SDK-BufferedWriter](https://help.aliyun.com/document_detail/51328.html?spm=5176.7751826.2.2.pelz68) 接口上传数据，该接口对用户屏蔽了 blockId 的细节，并且内部带有数据缓存区，会自动进行失败重试 。  
    下载数据时，Reader 也有类似机制，若长时间没有网络 IO 会被断开连接，建议 Read 过程连续进行中间不穿插其他系统的接口 。

6. MaxCompute Tunnel 目前有哪些语言的 SDK？  
    MaxCompute Tunnel 目前有 Java 及 C++ 版的 SDK 。

7. MaxCompute Tunnel 是否支持多个客户端同时上传同一张表？  
    支持

8. MaxComputeTunnel 适合批量上传还是流式上传？  
    MaxCompute Tunnel用于批量上传，不适合流式上传，流式上传可以使用 [DataHub高速流式数据通道](https://help.aliyun.com/knowledge_detail/47439.html?spm=5176.7751826.2.4.mnSxEs)，毫秒级延时写入 。

9. MaxCompute Tunnel 上传数据时一定要先存在分区吗？  
    是的，Tunnel 不会自动创建分区 。

10. Dship 与 MaxCompute Tunnel的关系？  
    Dship 是一个工具，通过 MaxCompute Tunnel 来上传下载 。
    ps: 感觉Dship是console客户端的前身

11. Tunnel upload 数据的行为是追加还是覆盖？  
    追加的模式 。

12. Tunnel 路由功能是怎么回事？  
    路由功能指的是 Tunnel SDK 通过设置 MaxCompute 获取 Tunnel Endpoint 的功能。因此，SDK 可以只设置 MaxCompute 的 endpoint 来正常工作 。

13. 用 MaxCompute Tunnel 上传数据时，一个 block 的数据量大小多大比较合适？  
    没有一个绝对最优的答案，要综合考虑网络情况，实时性要求，数据如何使用以及集群小文件等因素。一般，如果数量较大是持续上传的模式，可以在 64M - 256M， 如果是每天传一次的批量模式，可以设大一些到 1G 左右 。

14. 使用 MaxCompute Tunnel 下载, 总是提示 timeout？  
    一般是 endpoint 错误，请检查 Endpoint 配置，简单的判断方法是通过 telnet 等方法检测网络连通性 。

15. 通过 MaxCompute Tunnel 下载，抛出 You have NO privilege ‘odps:Select‘ on {acs:odps:*:projects/XXX/tables/XXX}. project ‘XXX‘ is protected 的异常 ?  
    该 project 开启了数据保护功能，用户操作这是从一个项目的数据导向另一个项目，这需要该 project 的 owner 操作 。

16. Tunnel 上传抛出异常 ErrorCode=FlowExceeded, ErrorMessage=Your flow quota is exceeded(超出).**?    
    Tunnel 对请求的并发进行了控制，默认上传和下载的并发 Quota 为 2000，任何相关的请求发出到结束过程中均会占用一个 Quota(配额) 单位 。若出现类似错误，有如下几种建议的解决方案：
    1. sleep 一下再重试；
    2. 将 project 的 tunnel 并发 quota 调大，需要联系管理员评估流量压力；
    3. 报告 project owner 调查谁占用了大量并发 quota，控制一下 。

17. Tunnel 上传时每个 Session 的生命周期是一天，因源表数据太大，导致 Session 超时任务失败？  
    建议把源表拆分成 2 个任务分开跑
